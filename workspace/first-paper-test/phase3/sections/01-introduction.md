## 1. Introduction

Natural language interfaces to databases promise to democratize data access by enabling non-technical users to query complex enterprise systems using everyday language. However, this vision remains largely unrealized at enterprise scale. Real-world banking environments contain 35,287 tables distributed across 9 schemas and 83 topic areas, with 163,284 business indicators and 39,558 standardized business terms — a data landscape orders of magnitude more complex than the benchmarks that dominate current research. While recent advances in large language models (LLMs) have pushed accuracy on the Spider benchmark from 70% to over 87% [DIN-SQL, DAIL-SQL, MAC-SQL], these systems assume small, well-documented schemas with fewer than 200 tables. The performance gap becomes stark on more realistic benchmarks: the Bird dataset, which features larger databases with external knowledge requirements, reveals accuracy drops to 54-73% [Bird, CHESS]. No existing system addresses the fundamental challenge of natural language querying over tens of thousands of tables spanning multiple business domains.

The core difficulty lies in bridging the semantic gap between business-level questions and physical database structures. A business analyst asking "查询各分行中小企业贷款余额" (query the SME loan balance for each branch) must navigate from high-level business concepts (SME loans, branches) through intermediate organizational structures (schemas, topics) to specific physical tables and fields — a mapping that requires deep domain knowledge. Traditional approaches fall into three categories, each with critical limitations. First, standalone LLMs hallucinate table and field names when confronted with enterprise-scale schemas they cannot systematically navigate [LLM-SQL Survey]. Second, retrieval-augmented generation (RAG) systems use vector similarity to retrieve relevant schema elements, but semantic similarity alone cannot capture the hierarchical business logic and data lineage relationships that govern enterprise data architectures [GraphRAG]. Third, ontology-based data access (OBDA) systems like Ontop provide structured mediation through formal ontologies, but they require rigid SPARQL queries and cannot handle the ambiguity inherent in natural language [Ontop, DL-Lite].

### 1.1 Key Insight: Ontology as Cognitive Hub

We propose a fundamentally different approach: transforming a domain ontology from passive knowledge storage into an active cognitive layer that guides LLM-based reasoning. Drawing on cognitive architecture theory [ACT-R, SOAR, CoALA], we formalize this as:

```
Ontology Layer (declarative memory) + Skills (procedural memory) = Cognitive Hub (domain cognition)
```

This formulation reframes the natural language querying problem from information retrieval to cognitive architecture design. The ontology serves as externalized long-term declarative memory — a structured representation of business concepts, data assets, and their relationships. Specialized Skills encode procedural knowledge — cognitive strategies for navigating different dimensions of this knowledge space. The LLM acts as a pattern-matching engine that coordinates between declarative and procedural memory, much as the central production system in ACT-R coordinates across modular buffers [Anderson et al., 2004].

The Cognitive Hub architecture enables three orthogonal navigation strategies, each exploring a distinct knowledge dimension. The Indicator Expert navigates a 5-level business indicator hierarchy (SECTOR→CATEGORY→THEME→SUBPATH→INDICATOR) containing 163,284 nodes, mapping business concepts to physical fields through 147,464 pre-computed associations. The Scenario Navigator follows convergent paths through the data asset topology (SCHEMA→TABLE_TOPIC→TABLE) across 35,379 nodes, combining structural navigation with semantic retrieval. The Term Analyst searches 39,558 business terms and 761 data standards to discover field-level mappings. These strategies are complementary by design: they explore orthogonal knowledge dimensions and produce independent evidence about the target data.

Critically, these strategies execute serially rather than in parallel, with each strategy inheriting context from its predecessors through the shared conversation history — a form of digital stigmergy [Grasse, 1959]. This design choice is not arbitrary but theoretically grounded: we prove via information theory that serial execution with implicit context inheritance produces a semantic cumulative effect, monotonically reducing information entropy about the target data. Formally, if S₁, S₂, S₃ denote the three strategies and I denotes the target table identity, then:

```
H(I | S₁, S₂, S₃) ≤ H(I | S₁, S₂) ≤ H(I | S₁) ≤ H(I)
```

where H denotes Shannon entropy. The inequality is strict when strategies explore orthogonal knowledge dimensions, which our three-layer ontology guarantees by construction. This formalization explains why serial execution with context sharing outperforms parallel independent execution: each successive strategy operates on a reduced uncertainty space defined by its predecessors' discoveries.

### 1.2 System Architecture and Key Innovations

Smart Query implements the Cognitive Hub architecture through several integrated innovations. The three-layer ontology (314,680 nodes, 623,118 relationships) separates business indicators, data assets, and business terms into distinct layers with rich cross-layer associations. This separation enables the three orthogonal navigation strategies while maintaining semantic coherence through shared physical table references.

Each strategy produces a structured evidence pack containing candidate tables, confidence scores, and reasoning traces. These independent evidence packs undergo cross-validation adjudication: three-strategy consensus yields high confidence, two-strategy agreement yields medium-high confidence, and single-strategy recommendations receive cautious confidence. This graded confidence mechanism is more rigorous than simple voting, as it operates on structured evidence rather than binary predictions.

After primary table selection, lineage-driven JOIN discovery leverages 50,509 pre-computed UPSTREAM relationships reflecting actual ETL data flow. This design embodies a key insight: for relational operations like JOINs, structural facts about data lineage are inherently more reliable than semantic similarity guesses from vector search. The system automatically infers JOIN conditions by identifying shared business terms across lineage-connected tables.

Isolated table filtering provides zero-maintenance data quality assurance through graph-theoretic analysis. Tables with in-degree and out-degree both equal to zero are automatically excluded as deprecated or orphaned assets, analogous to ACT-R's base-level activation decay where unused knowledge becomes inaccessible [Anderson et al., 2004].

The system exposes 29+ MCP (Model Context Protocol) tools that serve as the interface between LLM working memory and the externalized ontology. These tools implement hybrid retrieval combining keyword search and vector similarity, hierarchical path navigation, lineage traversal, and metadata enrichment — providing the LLM with structured access to domain knowledge at multiple granularities.

### 1.3 Contributions

This paper makes five primary contributions:

**C1: Cognitive Hub Architecture.** We introduce the Cognitive Hub architecture that transforms domain ontologies from passive knowledge storage into active cognitive layers for LLM-based reasoning. Grounded in cognitive architecture theory (ACT-R, SOAR, CoALA), this approach separates declarative memory (ontology) from procedural memory (Skills) and coordinates them through an LLM pattern-matching engine. To our knowledge, this is the first system to apply cognitive architecture principles to enterprise-scale natural language data querying.

**C2: Multi-Strategy Serial Execution with Stigmergic Context Inheritance.** We propose a novel multi-agent coordination pattern where three specialized strategies execute serially with implicit context inheritance through shared conversation history. This Pipeline-Blackboard Hybrid with Stigmergic Context Inheritance combines deterministic serial scheduling, shared evidence accumulation, and implicit communication. Evidence pack fusion with cross-validation adjudication provides graded confidence scoring based on inter-strategy agreement.

**C3: Semantic Cumulative Effect.** We provide an information-theoretic formalization proving that serial execution with implicit context inheritance monotonically reduces information entropy about the target data. The proof via the chain rule of conditional entropy establishes conditions for strict inequality (orthogonal knowledge dimensions) and identifies failure modes (redundancy, noise introduction, context degradation). This transforms an engineering observation into a theoretical principle with actionable design implications.

**C4: Intelligent Search Space Reduction.** We introduce several mechanisms for ontology-guided search space reduction: (1) lineage-driven JOIN discovery using pre-computed ETL relationships rather than semantic similarity, (2) isolated table filtering through graph-theoretic connectivity analysis, (3) dual retrieval combining structural navigation with semantic search, and (4) hierarchical path-based disambiguation. These mechanisms leverage the ontology's structural properties to constrain the search space systematically.

**C5: Comprehensive Evaluation.** We present controlled experiments on 100 real banking queries across four complexity categories (Simple, Medium, Complex, Adversarial) against five baselines spanning the design space: no ontology (Direct LLM), no structure (RAG), single strategy (three variants), no context sharing (Independent Agents), and no serial ordering (Parallel Execution). Six ablation studies isolate each architectural component's contribution. We directly measure the semantic cumulative effect through Shannon entropy reduction across strategy stages, providing empirical validation of the theoretical prediction.

### 1.4 Paper Organization

The remainder of this paper is organized as follows. Section 2 surveys related work across four research areas: natural language to SQL, ontology-based data access, LLM-based multi-agent systems, and knowledge graph-enhanced LLM reasoning. Section 3 presents the system architecture, detailing the three-layer ontology design, the three-strategy serial execution mechanism, evidence pack fusion, and lineage-driven JOIN discovery. Section 4 provides theoretical analysis of the semantic cumulative effect, multi-agent coordination properties, and cognitive architecture formalization. Section 5 describes the experimental setup, including the BankQuery-100 dataset, evaluation metrics, and baseline systems. Section 6 presents main results, ablation studies, entropy analysis, and case studies. Section 7 discusses key findings, limitations, and generalizability. Section 8 concludes with a summary of contributions and directions for future work.
