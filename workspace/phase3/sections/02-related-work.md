## 2. Related Work

Smart Query sits at the intersection of four research areas: natural language to SQL translation, ontology-based data access, LLM-based multi-agent systems, and knowledge graph-enhanced LLM reasoning. We survey each area, identify key limitations, and position our contributions relative to the state of the art.

### 2.1 Natural Language to SQL: From Benchmarks to Enterprise Scale

The past five years have witnessed remarkable progress in natural language to SQL (NL2SQL) translation, driven by increasingly powerful language models and sophisticated prompting strategies. Early neural approaches achieved 70% accuracy on the Spider benchmark [Spider2018], while recent LLM-based systems push beyond 87% through task decomposition and self-correction [DIN-SQL2023, DAIL-SQL2023]. DIN-SQL decomposes the NL2SQL task into four sequential subtasks — schema linking, query classification, SQL generation, and self-correction — achieving 85.3% execution accuracy on Spider through GPT-4-based reasoning [DIN-SQL2023]. RESDSQL introduces ranking-enhanced schema linking that decouples table/column selection from SQL generation, reaching 79.9% test accuracy [RESDSQL2023].

Multi-agent collaboration represents the current frontier. MAC-SQL employs three specialized agents — a Selector for schema pruning, a Decomposer for query breakdown, and a Refiner for iterative correction — achieving 86.8% accuracy on Spider [MAC-SQL2024]. This multi-agent paradigm parallels our three-strategy architecture, but MAC-SQL operates on raw database schemas without structured domain knowledge. CHESS takes a different approach, using a four-phase contextual retrieval pipeline that matches entity values from the database to ground LLM reasoning, achieving 72.7% accuracy on the more challenging Bird benchmark [CHESS2024].

The Bird benchmark reveals a critical gap between research benchmarks and real-world deployment. While Spider contains 200 databases with an average of fewer than 10 tables each, Bird features 95 databases totaling 33.4 GB with external knowledge requirements and dirty values [Bird2024]. Performance drops sharply: the best systems achieve only 54-73% accuracy on Bird compared to 85%+ on Spider. Yet even Bird's largest databases contain hundreds, not tens of thousands, of tables. No existing NL2SQL system addresses the enterprise-scale scenario we target: 35,287 tables distributed across 9 schemas and 83 topic areas, with complex hierarchical business logic and data lineage relationships that cannot be captured through schema linking alone.

The fundamental limitation of current NL2SQL approaches is their reliance on statistical schema linking — using vector similarity or LLM reasoning to select relevant tables and columns from raw database metadata. This approach works for small, well-documented schemas but fails at enterprise scale where semantic similarity alone cannot navigate the hierarchical business structures and data governance relationships that organize enterprise data architectures. Smart Query addresses this gap through ontology-guided navigation that encodes business logic, data lineage, and governance relationships as structured knowledge.

### 2.2 Ontology-Based Data Access: From Formal Mappings to Flexible Reasoning

Ontology-based data access (OBDA) provides an intellectual foundation for our work, though we depart significantly from its formal paradigm. The OBDA tradition, exemplified by systems like Ontop [Ontop2017] and theoretical frameworks like DL-Lite [DL-Lite2008], uses formal ontologies as mediators between high-level conceptual queries and low-level database schemas. Users express queries in SPARQL over an OWL 2 QL ontology, which the system rewrites into SQL through R2RML mappings [Lenzerini2002]. This approach provides formal correctness guarantees: if the ontology and mappings are sound, query results are provably correct.

Virtual Knowledge Graph (VKG) systems demonstrate OBDA's practical viability, with enterprise deployments at Statoil, Siemens, and other organizations [VKG2019]. These systems treat the ontology as a virtual layer over existing databases, avoiding data duplication while providing conceptual access. Extensions to temporal data [TemporalOBDA2019] and other specialized domains show the paradigm's flexibility within its formal constraints.

However, OBDA's strength — formal correctness — is also its limitation. The paradigm requires rigid R2RML mappings that must be manually constructed and maintained, and users must formulate queries in SPARQL, a formal query language that cannot accommodate the ambiguity and incompleteness inherent in natural language. When a business analyst asks "查询各分行中小企业贷款余额" (query the SME loan balance for each branch), they cannot express this directly in SPARQL; the query must be translated into a formal representation that precisely specifies entities, properties, and relationships.

Smart Query retains OBDA's core insight — that ontologies should mediate between business concepts and physical data — but replaces formal query rewriting with LLM-based flexible reasoning. We trade formal correctness guarantees for the ability to handle ambiguous natural language queries, incomplete specifications, and exploratory information needs. Our ontology serves not as a passive mapping layer but as an active cognitive hub that guides multi-strategy exploration. Where OBDA systems provide a single formal path from concept to data, we provide three orthogonal navigation strategies that produce independent evidence, enabling cross-validation and confidence calibration. This shift from formal to probabilistic reasoning is essential for natural language interfaces at enterprise scale.

### 2.3 LLM-Based Multi-Agent Systems

The emergence of LLMs as general-purpose reasoning engines has sparked intense interest in multi-agent architectures that decompose complex tasks across specialized agents. AutoGen provides a flexible framework for multi-agent conversation with customizable communication patterns [AutoGen2023], while MetaGPT introduces standardized operating procedures (SOPs) that structure agent collaboration through role specialization and artifact-based communication [MetaGPT2023]. ChatDev applies a sequential chat chain paradigm to software development, with role-playing agent pairs (CEO-CTO, programmer-reviewer) collaborating through explicit dialogue [ChatDev2023].

These systems demonstrate that multi-agent decomposition can improve performance on complex tasks, but they rely on explicit communication mechanisms. AutoGen agents exchange structured messages, MetaGPT agents subscribe to shared memory pools, and ChatDev agents engage in scripted dialogues. CAMEL introduces role-playing with inception prompting to induce cooperative behavior [CAMEL2023], while recent work on multi-agent debate shows that parallel agents arguing from diverse perspectives can improve factual accuracy [Debate2023].

A critical gap in existing LLM-based multi-agent systems is the lack of principled justification for coordination mechanisms. Why should agents communicate explicitly rather than implicitly? Why execute serially rather than in parallel? When does multi-agent decomposition improve over single-agent reasoning? These questions remain largely unanswered in the literature. The LLM-based agents survey identifies coordination and long-term planning as open challenges [LLMAgentSurvey2023], noting that most systems rely on heuristic designs without theoretical grounding.

Smart Query introduces implicit context inheritance through shared conversation history — a form of digital stigmergy where agents communicate by observing the traces left by their predecessors rather than through explicit messages [Grasse1959]. This design choice is not arbitrary but theoretically motivated: we prove via information theory that serial execution with implicit context inheritance produces a semantic cumulative effect, monotonically reducing information entropy about the target data. Formally, if S₁, S₂, S₃ denote the three strategies and I denotes the target table identity, then H(I | S₁, S₂, S₃) ≤ H(I | S₁, S₂) ≤ H(I | S₁) ≤ H(I), where H denotes Shannon entropy. This formalization provides the first principled justification for serial over parallel execution in LLM-based multi-agent systems.

Our evidence pack fusion mechanism also differs from existing approaches. Where multi-agent debate systems use voting or averaging to aggregate agent outputs [Debate2023], we perform cross-validation adjudication on structured evidence packs, producing graded confidence scores (high for three-strategy consensus, medium-high for two-strategy agreement, cautious for single-strategy recommendations). This approach is more rigorous than simple voting because it operates on structured evidence — candidate tables with reasoning traces — rather than binary predictions.

### 2.4 Knowledge Graph-Enhanced LLM Reasoning

The integration of knowledge graphs (KGs) with LLMs has emerged as a promising approach to reduce hallucination and improve factual grounding. Comprehensive surveys document 25-60% hallucination reduction when LLM reasoning is augmented with structured knowledge [KG-LLM-Roadmap2024, KG-LLM-Survey2024]. Think-on-Graph demonstrates that LLM-guided beam search over knowledge graphs can improve multi-hop reasoning on knowledge graph question answering (KGQA) tasks by 10-20% [Think-on-Graph2024]. The system uses an LLM to score exploration paths through a general knowledge graph, combining neural pattern matching with symbolic structure.

GraphRAG introduces hierarchical knowledge graph construction with community detection, enabling both local and global query answering over document collections [GraphRAG2024]. The system builds a KG dynamically from text, clusters nodes into communities, and generates summaries at multiple granularities. This hierarchical structure enables more comprehensive retrieval than flat vector search, though the approach targets document-based question answering rather than database querying.

StructGPT provides specialized interfaces for LLM reasoning over structured data, including tables, knowledge graphs, and databases [StructGPT2023]. The system defines iterative reading and reasoning operations that allow LLMs to navigate structured data systematically. However, StructGPT uses generic interfaces that do not exploit domain-specific structure or relationships.

The fundamental limitation of existing KG+LLM work is its reliance on general-purpose knowledge graphs (Wikidata, Freebase) or dynamically constructed graphs from text. These approaches treat the KG as a passive retrieval source — a structured database to be queried — rather than an active cognitive layer that guides reasoning. They typically employ a single retrieval or exploration strategy, missing the opportunity for multi-perspective evidence collection and cross-validation.

Smart Query differs in several key respects. First, we use a purpose-built enterprise ontology (314,680 nodes, 623,118 relationships) constructed through a 21-step ETL pipeline from actual database metadata, data lineage, and business glossaries. This ontology encodes domain-specific business logic, data governance relationships, and ETL lineage that cannot be captured in general KGs. Second, we treat the ontology as an active cognitive hub rather than a passive retrieval source, with three orthogonal navigation strategies that explore different knowledge dimensions (business indicators, data asset topology, business terminology). Third, our cross-layer associations (147,464 HAS_INDICATOR edges, 251,227 HAS_TERM edges) enable multi-perspective discovery where different navigation paths converge on the same physical tables, providing natural cross-validation. Fourth, we leverage pre-computed structural relationships (50,509 UPSTREAM lineage edges) for lineage-driven JOIN discovery, embodying the insight that structural facts about data flow are more reliable than semantic similarity guesses for relational operations.

Table 7 summarizes the positioning of Smart Query relative to representative systems from each research area. Smart Query is unique in combining ontology-driven cognitive architecture, multi-agent serial execution with implicit context inheritance, evidence pack fusion with graded confidence, and enterprise-scale deployment (35,000+ tables). While individual components have precedents — OBDA systems use ontologies, MAC-SQL uses multiple agents, Think-on-Graph uses KG-guided reasoning — no existing system integrates these elements into a unified cognitive architecture with information-theoretic justification for its design choices.

(see Table 7)
