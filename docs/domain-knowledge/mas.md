# MAS 领域知识

## 概述

本文档提供多智能体系统（MAS）领域的统一知识基础，同时服务于：
- **Phase 1 理论分析**：将目标系统映射到经典 MAS 范式、认知架构和形式化框架
- **Phase 4 领域评审**：提供 MAS 领域的评估维度、常见问题和评审要点

## 调用方式

**Phase 1**: `Skill(skill="domain-knowledge-mas", args="{project}")`
**Phase 4**: 评审专家直接读取本 Skill 获取领域评审标准

## 约束条件

- **禁止 WebSearch**：所有分析均基于 LLM 知识和本文件中的领域知识
- **可用工具**：仅限 Read、Write、Glob、Grep
- **输出文件**：`workspace/{project}/phase1/skill-mas-theory.json`

---

## 第一层：核心理论知识

### MAS 范式映射

对以下六种经典 MAS 范式，评估其与目标系统的相关性。对每种范式，生成 `similarity_score`（0.0 到 1.0）、`matching_aspects`、`diverging_aspects` 和 `relevance_assessment`。

#### 1. BDI（Belief-Desire-Intention）架构

**核心理论**：Rao & Georgeff (1995)。智能体维护关于世界的信念（beliefs）、愿望（desires/goals）和意图（intentions/committed plans）。

**关键特征**：
- 显式心智态度（信念、愿望、意图）
- 具有上下文敏感计划选择的计划库
- 手段-目的推理将目标分解为子目标
- 承诺策略（盲目、单一、开放）

**映射指导**：查看目标系统的智能体是否具有显式目标表示、维护关于任务状态的信念、并从备选计划中选择。基于 LLM 的智能体通常具有隐式 BDI——提示词编码信念和愿望，LLM 的推理充当审议循环。

#### 2. Blackboard 架构

**核心理论**：Nii (1986)、Hayes-Roth (1985)。一个共享数据结构（黑板）由多个专家知识源（KSs）增量构建。

**关键特征**：
- 中央共享解空间
- 独立的知识源读写黑板
- 机会主义问题求解
- 用于调度的控制壳

**映射指导**：查找多个智能体贡献的共享产物、共享上下文或共享状态。基于文件的协调（智能体写入共享工作区）是 Blackboard 的现代形式。

#### 3. Contract Net Protocol

**核心理论**：Smith (1980)。管理者智能体发布任务；承包者智能体评估并投标；管理者将合同授予最佳投标者。

**关键特征**：
- 任务发布/投标/授予循环
- 去中心化任务分配
- 智能体自评能力

**映射指导**：查找动态任务分配或基于能力的路由。大多数基于 LLM 的 MAS 使用静态角色分配而非 Contract Net。

#### 4. Shared Memory / Tuple Space

**核心理论**：Gelernter (1985)、Linda 协调语言。智能体通过共享关联内存（元组空间）协调。

**关键特征**：
- 解耦通信
- 时间解耦
- 按模式关联访问

**映射指导**：查找智能体用于协调的共享数据存储或文件系统。

#### 5. Pipeline / Assembly Line 架构

顺序处理，每个阶段执行专门的转换。阶段 N 的输出成为阶段 N+1 的输入。

**关键特征**：
- 线性流程
- 阶段专业化
- 阶段间的中间表示
- 吞吐量受瓶颈限制

**映射指导**：查找智能体按定义顺序运行且每个智能体的输出馈入下一个的顺序阶段执行。

#### 6. Stigmergy

**核心理论**：Grasse (1959)、Theraulaz & Bonabeau (1999)。智能体通过修改共享环境间接协调。

**关键特征**：
- 通过环境修改的间接通信
- 基于局部规则的自组织行为
- 无需中央协调器
- 可扩展

**映射指导**：查找隐式上下文继承，即智能体的输出修改共享环境，后续智能体根据发现的内容进行适应。

### 认知架构分析

将目标系统映射到三种已建立的认知架构。对每种架构，生成 `component_mappings`、`match_quality`（low/moderate/high）和 `gaps`。

#### 1. ACT-R（Adaptive Control of Thought — Rational）

**核心理论**：Anderson (1993, 2007)。一种混合认知架构。

**组件**：
- **陈述性记忆**：通过扩散激活访问的事实知识块
- **程序性记忆**：产生式规则（IF 条件 THEN 动作）
- **目标缓冲区**：当前目标栈
- **感知-运动模块**：环境接口
- **亚符号层**：激活水平、效用值

**映射指导**：将知识存储映射到陈述性记忆，智能体提示词/决策逻辑映射到产生式规则，任务队列/阶段进展映射到目标缓冲区。

#### 2. SOAR（State, Operator, And Result）

**核心理论**：Laird, Newell & Rosenbloom (1987)。一种统一认知架构。

**组件**：
- **工作记忆**：当前情境
- **长期记忆**：程序性、语义性、情景性
- **决策循环**：输入、精化、提议、决定、应用、输出
- **僵局解决**：停滞时创建子目标
- **组块化**：从僵局解决中学习新规则

**映射指导**：将共享上下文/工作区映射到工作记忆，智能体知识库映射到长期记忆类型，编排循环映射到决策循环。

#### 3. Global Workspace Theory（GWT）

**核心理论**：Baars (1988, 2005)。一种意识理论。

**组件**：
- **全局工作空间**：共享广播媒介
- **专家处理器**：无意识、并行、领域特定
- **意识广播**：获胜联盟的内容全局广播
- **注意力**：竞争性选择以获取工作空间访问权

**映射指导**：将共享状态映射到全局工作空间，单个智能体映射到专家处理器，协调器逻辑映射到注意力机制。

### 信息论形式化框架

仅当 input-context.md 明确提及信息论属性、熵减少或跨智能体信息增益时执行。

**形式化框架**：
1. **定义信息空间**：令 X 为表示任务输出空间的随机变量。H(X) 为处理前的 Shannon entropy。
2. **建模顺序处理**：对于流水线智能体 A_1...A_n，定义 H(X | A_1,...,A_k) 为 k 个智能体处理后的剩余不确定性。
3. **单调熵减少**：如有主张，形式化条件——共享上下文访问、胜任的专家、可分解的任务。
4. **互信息**：将 A_{k+1} 的增益表示为 I(X; A_{k+1} | A_1,...,A_k)。
5. **串行与并行比较**：当智能体具有互补专长时，证明 I_serial >= I_parallel。
6. **失败条件**：系统性偏差、零互信息、上下文溢出。

### 证据/产物融合形式化

仅当目标系统组合来自多个智能体的证据/产物时执行。

**选项**（选择最合适的）：
1. **Dempster-Shafer Theory**：用于信念质量组合。评估独立性假设。
2. **Bayesian Evidence Combination**：用于具有顺序更新的概率评估。
3. **Weighted Voting / Ensemble Theory**：用于离散输出聚合。分析 Condorcet 条件。
4. **Structured Artifact Accumulation**：用于组合结构化产物（JSON、文档）。形式化为具有连接操作的偏序解格。

---

## 第二层：评审标准

### 核心概念与评估维度

#### BDI Architecture (Belief-Desire-Intention)

**期望用法**：
- 应正确定义 BDI 模型的三个组件（信念、愿望、意图）
- 说明信念更新机制（感知、学习）
- 描述意图的生成和放弃策略
- 讨论 deliberation 与 means-ends reasoning

**常见问题**：
- 与规划系统混淆，忽视 BDI 的反应性特点
- 忽略信念更新机制和不确定性处理
- 意图管理策略不清晰
- 未讨论 BDI 与实际执行的差距

**评审要点**：
- 检查 BDI 架构是否完整定义
- 验证信念更新的机制是否合理
- 评估意图选择的策略是否有效
- 确认是否讨论了承诺度（degree of commitment）

#### Agent Communication

**期望用法**：
- 应说明通信协议（FIPA ACL, KQML, 或自定义）
- 定义消息格式和语义（speech acts）
- 讨论通信开销和可靠性
- 处理消息顺序和并发

**常见问题**：
- 忽视通信开销和延迟
- 未讨论消息可靠性保证
- 缺少对通信失败的处理
- 混淆不同层的通信（应用层 vs 传输层）

**评审要点**：
- 检查通信协议的选择是否合理
- 评估通信语义的定义是否完整
- 验证是否考虑了异步通信和消息队列
- 确认是否有消息过滤和聚合机制

#### Coordination Protocols

**期望用法**：
- 应描述协调机制（Contract Net, Blackboard, Voting, 协商）
- 分析协调策略与任务特性的匹配
- 讨论协调开销与收益的权衡
- 考虑协调的可扩展性

**常见问题**：
- 协调策略与任务特性不匹配
- 缺乏死锁分析和避免机制
- 忽视协调开销（通信、同步）
- 未讨论容错和恢复

**评审要点**：
- 检查协调机制的选择是否有理论依据
- 评估协调协议的正确性（无死锁、活锁）
- 验证是否分析了协调开销
- 确认是否有动态协调调整机制

#### Emergent Behavior

**期望用法**：
- 应分析个体行为如何涌现为集体行为
- 提供涌现性的验证方法
- 讨论个体最优与集体最优的关系
- 考虑涌现行为的可控性

**常见问题**：
- 缺乏涌现性验证和分析
- 假设个体最优会导致集体最优（错误）
- 未讨论涌现的预测和控制
- 混淆简单聚合与真正涌现

**评审要点**：
- 检查是否提供了涌现性的定义和验证
- 评估是否分析了宏观-微观的映射关系
- 验证是否考虑了涌现的可控性
- 确认是否有定量分析（如涌现度量）

#### Agent Organization

**期望用法**：
- 应说明组织结构（层次、扁平、混合、动态）
- 讨论角色和权限的定义
- 考虑组织的可扩展性
- 分析组织演化机制

**常见问题**：
- 忽视可扩展性分析
- 缺少中心化/去中心化的权衡分析
- 角色定义不清晰
- 未讨论组织的动态调整

**评审要点**：
- 检查组织结构的选择是否与应用场景匹配
- 评估角色和关系的定义是否清晰
- 验证是否分析了可扩展性
- 确认是否有组织演化机制

### 领域评审维度

#### 1. MAS 架构与经典范式对应

**评估标准**：
- 系统是否与经典 MAS 范式对应（BDI、Blackboard、Contract Net）
- 架构描述是否清晰（组件、交互、数据流）
- 是否有形式化或半形式化描述

**必引经典**：
- Wooldridge & Jennings (1995) — Intelligent Agents: Theory and Practice
- Rao & Georgeff (1991) — BDI Model
- Smith (1980) — Contract Net Protocol
- Jennings (1996) — Coordination

#### 2. 通信协议设计

**评估标准**：
- 通信协议的可扩展性和可靠性
- 消息语义的完整性
- 异步通信和并发处理
- 通信开销分析

**关键问题**：
- 使用什么通信协议（FIPA ACL, KQML, 自定义）？
- 如何处理消息丢失和顺序错乱？
- 是否有消息聚合和过滤？
- 通信开销如何影响系统性能？

#### 3. 协调机制与问题匹配

**评估标准**：
- 协调机制是否与问题特性匹配
- 是否有死锁/活锁分析
- 协调开销与收益的权衡
- 容错和恢复机制

**关键问题**：
- 协调策略如何与任务依赖关系匹配？
- 如何避免死锁？
- 协调开销如何度量？
- 如何处理智能体失败？

#### 4. 理论证明或形式化验证

**评估标准**：
- 是否有正确性证明
- 是否有复杂度分析
- 是否有形式化规范（如 Z, B, LTL）
- 是否有模型检查

**关键问题**：
- 协议的正确性如何证明？
- 系统的收敛性如何保证？
- 复杂度（时间、空间、通信）如何分析？

#### 5. 实验平台与可重复性

**评估标准**：
- 是否在标准 MAS 平台验证（JADE, Jason, MadKit）
- 是否有充分的数据集和基准
- 代码和数据是否公开
- 实验设置是否可重复

**关键问题**：
- 使用什么平台/框架？
- 与其他系统的比较是否公平？
- 代码和数据是否公开？

#### 6. 与最新 LLM-based MAS 对比

**评估标准**：
- 是否与最新的基于 LLM 的 MAS 系统对比
- 是否讨论了 LLM 带来的新机遇
- 是否分析了 LLM 的局限性

**SOTA 对比清单**：
- AutoGen (Microsoft)
- CrewAI
- MetaGPT
- AgentVerse
- ChatDev

### 常见评审陷阱

#### 陷阱 1：声称多智能体但实际只是集中式系统

**如何识别**：
- 所有决策都在中心节点进行
- 智能体之间没有真正的自主性
- 缺少智能体间的协商或协调

**如何避免误判**：
- 检查决策是否真的分布
- 确认智能体是否有自主行为
- 验证是否有真正的协调（而非指令）

#### 陷阱 2：忽视通信开销和延迟

**如何识别**：
- 理论分析假设零通信成本
- 实验在小规模网络进行
- 没有讨论网络延迟的影响

**如何避免误判**：
- 检查是否有通信开销分析
- 确认实验规模是否充分
- 验证是否考虑了网络特性

#### 陷阱 3：协调协议与任务特性不匹配

**如何识别**：
- 使用 Contract Net 处理高度依赖的任务
- 使用 Blackboard 但没有共享知识表示
- 协调机制的选择没有理论依据

**如何避免误判**：
- 检查任务依赖分析
- 确认协调机制的选择依据
- 验证是否分析了匹配度

#### 陷阱 4：缺乏对系统收敛性的证明

**如何识别**：
- 声称系统能达成一致，但没有证明
- 只有实验结果，没有理论分析
- 未讨论不收敛的情况

**如何避免误判**：
- 检查是否有收敛性证明
- 确认是否分析了不收敛的情况
- 验证收敛条件是否明确

#### 陷阱 5：未讨论安全性和恶意智能体

**如何识别**：
- 假设所有智能体都是诚实的
- 没有考虑恶意智能体的攻击
- 缺少安全机制

**如何避免误判**：
- 检查是否讨论了安全威胁模型
- 确认是否有防御机制
- 验证是否分析了恶意行为的影响

---

## 第三层：学术参考

### 经典文献对标表

| 论文 | 为什么重要 | 应在何处引用 |
|------|-----------|-------------|
| Wooldridge & Jennings (1995) | MAS 基础理论 | 引言、相关工作 |
| Rao & Georgeff (1991) | BDI 架构 | 方法-智能体模型 |
| Smith (1980) | Contract Net | 方法-协调 |
| Durfee & Lesser (1989) | 分布式问题求解 | 相关工作-协调 |
| Jennings (1996) | 承诺理论 | 方法-协作 |
| Shoham & Leyton-Brown (2008) | Multiagent Systems | 相关工作-综述 |

### SOTA 对比清单

**传统 MAS 系统**：JADE, Jason, MadKit, JACK

**现代 LLM-based MAS**：AutoGen, CrewAI, MetaGPT, AgentVerse, ChatDev

**协调协议**：Contract Net, Blackboard, Voting, 协商, 联合意图

**应用领域**：分布式优化、资源分配、：机器人协作、智能电网

### 领域特定评审问题

1. **BDI 模型完整性**：Agent 的 BDI 模型是否完整定义？信念如何更新？意图如何选择？

2. **通信可靠性**：通信协议如何处理消息丢失和顺序错乱？

3. **死锁分析**：协调机制是否能证明无死锁？

4. **可扩展性**：系统的可扩展性如何评估（节点数增加时的性能）？

5. **LLM 对比**：是否与最新的 AutoGen、CrewAI、MetaGPT 系统对比？

6. **组织演化**：组织结构是否动态调整？如何触发？

7. **容错性**：如何处理智能体失败？是否有恢复机制？

8. **承诺度**：智能体对意图的承诺度如何？是否有重新考虑机制？

9. **学习机制**：智能体是否能学习？学习什么（策略、模型、其他）？

10. **社会性**：智能体之间是否有社会规范？如何执行？

---

## Phase 1 执行步骤（理论分析模式）

### 步骤 1：读取输入上下文

读取 `workspace/{project}/phase1/input-context.md`，提取以下信息：
- 系统名称和用途
- 智能体/组件架构（多少个智能体，什么角色）
- 执行模型（串行、并行、层级、流水线、混合）
- 通信机制（显式消息、共享上下文、基于文件、隐式）
- 证据/产物积累方式（如有）
- 系统设计者提出的理论主张（信息论、收敛性等）
- 系统是否使用本体或知识图谱

### 步骤 2：执行 MAS 范式映射

对所有六种范式进行评估，生成相似度分数和映射分析。

### 步骤 3：执行认知架构分析

将目标系统映射到 ACT-R、SOAR 和 GWT 三种架构。

### 步骤 4：信息论形式化（如适用）

仅当输入上下文明确提及信息论属性时执行。

### 步骤 5：证据/产物融合形式化（如适用）

仅当目标系统组合来自多个智能体的证据/产物时执行。

### 步骤 6：综合发现

将所有分析整合为连贯的理论叙事。

### 步骤 7：写入输出 JSON

写入 `workspace/{project}/phase1/skill-mas-theory.json`，遵循输出格式规范。

## Phase 1 输出格式

```json
{
  "skill_id": "domain-knowledge-mas",
  "domain": "multi_agent_systems",
  "status": "complete",
  "summary": "...",
  "findings": [
    {
      "finding_id": "F1",
      "type": "theory|method|comparison|architecture",
      "title": "...",
      "description": "...",
      "evidence": "...",
      "related_innovations": [1, 3],
      "academic_significance": "..."
    }
  ],
  "domain_specific_data": {
    "paradigm_mapping": {
      "paradigms": [...],
      "primary_paradigm": "...",
      "secondary_paradigms": [...],
      "justification": "...",
      "novel_elements": [...]
    },
    "cognitive_architecture_analysis": {
      "act_r_mapping": {...},
      "soar_mapping": {...},
      "gwt_mapping": {...},
      "novel_aspects": [...]
    },
    "formalization": {
      "information_theoretic": {...},
      "fusion_formalization": {...}
    }
  }
}
```

## 质量标准

1. **所有 6 种范式均已评估** — 无遗漏范式，每种都有具体的相似度分数和映射
2. **所有 3 种认知架构均已映射** — ACT-R、SOAR 和 GWT 各有组件级映射
3. **范式映射有理有据** — 基于目标系统的架构，而非仅凭断言
4. **认知映射具体明确** — 具体的组件到组件映射，而非模糊类比
5. **识别新颖方面** — 目标系统做了什么是现有框架无法捕获的
6. **形式化数学上合理**（如存在）— 正确使用熵、条件熵、互信息
7. **发现可操作** — 每个发现为下游论文智能体提供理论弹药
8. **诚实面对局限** — 不完美的映射和强假设明确陈述
