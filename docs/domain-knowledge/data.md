# Domain Knowledge: Data Analysis & Machine Learning

## 概述

本文档提供 Data Analysis & Machine Learning 领域的完整知识支持，包含：
1. **理论分析**：数据预处理、特征工程、模型选择、评估方法
2. **评审认知框架**：核心概念、评估维度和评审方法论

**调用方式：** `Skill(skill="domain-knowledge-data", args="{project}")`

**输出：** `workspace/{project}/phase1/skill-data.json`

---

## Part 1: 理论分析

### 核心研究范式

1. **监督学习范式**：从标注数据学习预测模型
2. **无监督学习范式**：从无标注数据发现模式
3. **特征工程范式**：设计和选择有效特征
4. **模型集成范式**：组合多个模型提升性能

### 关键技术组件

#### 1. 数据预处理
- **缺失值处理**：删除、填充、插值
- **异常值检测**：统计方法、基于距离、基于密度
- **数据标准化**：归一化、标准化、正则化
- **数据平衡**：过采样、欠采样、SMOTE

#### 2. 特征工程
- **特征提取**：从原始数据提取有意义的特征
- **特征选择**：过滤法、包装法、嵌入法
- **特征变换**：PCA、LDA、t-SNE
- **特征交互**：多项式特征、交叉特征

#### 3. 模型选择与评估
- **模型类型**：线性模型、树模型、神经网络、集成模型
- **评估指标**：准确率、精确率、召回率、F1、AUC
- **交叉验证**：K-fold、留一法、时间序列分割
- **超参数优化**：网格搜索、随机搜索、贝叶斯优化

### 评估维度

1. **预测性能**：在测试集上的准确率和泛化能力
2. **计算效率**：训练时间和推理时间
3. **可解释性**：模型的可解释性和特征重要性
4. **鲁棒性**：对噪声和异常值的鲁棒性

---

## Part 2: 评审认知框架

### 核心概念与评估维度

#### 数据质量
- **期望用法**：说明数据来源、数据量、数据质量评估
- **常见问题**：忽视数据偏差和标注错误
- **评审要点**：检查数据集的代表性和质量

#### 特征工程
- **期望用法**：明确说明特征提取和选择方法
- **常见问题**：特征工程不充分，直接使用原始数据
- **评审要点**：验证特征的有效性和合理性

#### 模型评估
- **期望用法**：使用多种评估指标，进行交叉验证
- **常见问题**：只在训练集上评估，忽视过拟合
- **评审要点**：检查评估方法的严谨性

### 经典文献对标

| 论文 | 为什么重要 | 应在何处引用 |
|------|-----------|-------------|
| Breiman (2001) | Random Forest | 方法-集成学习 |
| Chen & Guestrin (2016) | XGBoost | 方法-梯度提升 |
| Goodfellow et al. (2016) | Deep Learning | 相关工作-深度学习 |
| Hastie et al. (2009) | 统计学习 | 相关工作-理论基础 |

### SOTA 对比清单

- **传统方法**：线性回归、逻辑回归、决策树、SVM
- **集成方法**：Random Forest、XGBoost、LightGBM、CatBoost
- **深度学习**：MLP、CNN、RNN、Transformer
- **AutoML**：Auto-sklearn、TPOT、H2O AutoML

### 领域特定评审问题

1. 数据来源是什么？数据量多大？
2. 如何处理缺失值和异常值？
3. 使用了哪些特征工程方法？
4. 特征选择的依据是什么？
5. 使用了哪些模型？为什么选择这些模型？
6. 评估指标是什么？是否充分？
7. 是否进行了交叉验证？
8. 如何处理过拟合？
9. 模型的可解释性如何？
10. 与 baseline 和 SOTA 的对比？
