---
name: review-se-domain
description: "Software Engineering 领域评审认知框架 — 提供敏捷/CI-CD/测试/代码质量领域的核心概念、评估维度和评审方法论"
---

# Review Software Engineering Domain Skill

## 领域认知框架

### 核心研究范式

Software Engineering 研究基于以下核心范式：

1. **工程化范式**：将系统化、量化的方法应用于软件开发
2. **迭代增量范式**：通过迭代和增量交付应对需求变化
3. **质量成本范式**：在开发早期投入质量保证，降低后期修复成本
4. **人本范式**：关注开发者体验、团队协作和组织文化

### 核心概念与评估维度

#### Agile Methodology

**期望用法**：
- 应正确应用敏捷原则（Scrum、Kanban、XP）
- 讨论迭代长度和节奏的选择
- 考虑敏捷实践与项目规模的匹配
- 避免形式化敏捷而非真正敏捷

**常见问题**：
- 形式化敏捷（只保留仪式，忽视价值观）
- 忽视技术债务的积累
- 迭代长度不合理
- 缺少对敏捷效果的度量

**评审要点**：
- 检查敏捷实践的选择是否合理
- 验证是否真正体现敏捷价值观
- 评估技术债务的管理
- 确认迭代节奏的合理性

#### CI/CD

**期望用法**：
- 应说明持续集成和部署流程
- 讨论自动化测试覆盖率
- 考虑部署策略（蓝绿部署、金丝雀发布）
- 监控和回滚机制

**常见问题**：
- CI pipeline 速度慢
- 部署失败率高
- 缺少自动化测试
- 没有回滚策略

**评审要点**：
- 检查 CI/CD 流程的完整性
- 验证自动化测试覆盖率
- 评估部署策略的选择
- 确认监控和回滚机制

#### Software Testing

**期望用法**：
- 应覆盖单元测试、集成测试、系统测试、验收测试
- 讨论测试覆盖率（语句、分支、路径）
- 考虑测试自动化和持续测试
- 包含性能测试和安全测试

**常见问题**：
- 测试覆盖率低
- 缺乏自动化测试
- 只关注功能测试，忽视非功能测试
- 测试金字塔不均衡

**评审要点**：
- 检查测试策略的完整性
- 验证测试覆盖率的报告
- 评估自动化程度
- 确认测试类型的均衡性

#### Code Quality

**期望用法**：
- 应讨论代码质量指标（复杂度、可维护性、可读性）
- 使用代码审查和静态分析
- 考虑代码规范和风格指南
- 定期重构

**常见问题**：
- 代码重复
- 缺乏重构
- 复杂度过高
- 没有代码审查机制

**评审要点**：
- 检查代码质量的度量
- 验证代码审查的实践
- 评估重构的频率和方法
- 确认静态分析的使用

#### Technical Debt

**期望用法**：
- 应评估和管理技术债务
- 讨论债务的优先级和偿还策略
- 考虑债务的利息（维护成本增加）
- 平衡新功能开发与债务偿还

**常见问题**：
- 忽视技术债务
- 债务不断积累
- 没有偿还计划
- 无法量化债务

**评审要点**：
- 检查是否有技术债务的识别
- 验证债务的量化和管理
- 评估偿还策略的合理性
- 确认债务与新开发的平衡

### 领域评审维度

#### 1. 工程严谨性

**评估标准**：
- 是否遵循软件工程最佳实践
- 流程是否规范和可重复
- 是否有质量保证机制

**必引经典**：
- Fowler (2000) — Refactoring
- Beck (2000) — Extreme Programming
- Hunt & Thomas (1999) — The Pragmatic Programmer
- Cockburn (2002) — Agile Software Development

#### 2. 与软件工程最佳实践对比

**评估标准**：
- 是否与业界标准对比
- 实践的合理性
- 改进的创新性

**关键问题**：
- 与哪些最佳实践对比？
- 实践选择是否合理？
- 有什么创新点？

#### 3. 工具和流程的有效性

**评估标准**：
- 工具选择是否合适
- 流程是否有效
- 是否有量化评估

**关键问题**：
- 使用了什么工具？
- 流程效果如何评估？
- 工具链是否完整？

#### 4. 开发效率和质量的提升

**评估标准**：
- 效率提升的量化
- 质量改进的证据
- 成本效益分析

**关键问题**：
- 效率如何提升？
- 质量如何改进？
- 成本效益如何？

#### 5. 实际项目应用和案例

**评估标准**：
- 是否有真实项目案例
- 案例的代表性
- 结果的可推广性

**关键问题**：
- 是否有真实案例？
- 案例规模如何？
- 结果是否可推广？

#### 6. 与最新 DevOps/MLOps 工具对比

**评估标准**：
- 是否与最新工具对比
- 工具链的完整性
- 与主流实践的对齐

**关键问题**：
- 与哪些工具对比？
- 工具链是否完整？
- 是否与主流实践对齐？

### 常见评审陷阱

#### 陷阱 1：过度工程化

**如何识别**：
- 系统设计过于复杂
- 引入不必要的抽象
- 过度设计未来需求

**如何避免误判**：
- 检查设计的必要性
- 确认 YAGNI 原则
- 验证复杂度的合理性

#### 陷阱 2：缺乏代码审查

**如何识别**：
- 没有提及代码审查
- 没有审查流程描述
- 质量保证不充分

**如何避免误判**：
- 检查代码审查的实践
- 确认审查流程
- 验证审查效果

#### 陷阱 3：忽视文档

**如何识别**：
- 缺少架构文档
- API 文档不完整
- 没有用户手册

**如何避免误判**：
- 检查文档的完整性
- 确认文档的维护
- 验证文档的质量

#### 陷阱 4：技术债务积累

**如何识别**：
- 没有技术债务的讨论
- 代码质量下降
- 缺少重构活动

**如何避免误判**：
- 检查技术债务的识别
- 确认债务的管理
- 验证重构的实践

#### 陷阱 5：测试不充分

**如何识别**：
- 测试覆盖率低
- 缺少自动化测试
- 只关注单元测试

**如何避免误判**：
- 检查测试覆盖率
- 确认测试自动化
- 验证测试类型的均衡

### 经典文献对标

#### 必引经典论文

| 论文 | 为什么重要 | 应在何处引用 |
|------|-----------|-------------|
| Fowler (2000) | 重构基础 | 相关工作-重构 |
| Beck (2000) | 极限编程 | 相关工作-敏捷 |
| Hunt & Thomas (1999) | 务实编程 | 引言-原则 |
| Cockburn (2002) | 敏捷软件开发 | 相关工作-敏捷 |
| Boehm (2000s) | 敏捷与计划平衡 | 相关工作-方法论 |

#### SOTA 对比清单

**敏捷方法**：Scrum, Kanban, XP, SAFe, LeSS

**CI/CD 工具**：Jenkins, GitLab CI, GitHub Actions, CircleCI

**测试工具**：JUnit, Selenium, Jest, PyTest

**代码质量工具**：SonarQube, ESLint, Pylint

### 领域特定评审问题

1. **敏捷适应**：敏捷流程如何适应团队规模和项目复杂度？

2. **CI/CD 失败处理**：CI/CD pipeline 如何处理测试失败？

3. **测试策略**：测试策略是否覆盖所有关键功能？

4. **技术债务量化**：如何量化和管理技术债务？

5. **代码质量**：代码质量如何持续改进？

6. **重构实践**：重构的频率和方法如何？

7. **团队协作**：团队协作如何支持工程实践？

8. **文档维护**：文档如何维护和更新？

9. **监控告警**：监控和告警如何设置？

10. **安全实践**：安全实践如何集成到开发流程？
